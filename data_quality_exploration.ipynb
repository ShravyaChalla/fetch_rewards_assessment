{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fetch_rewards as fr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_df = fr.load_brands_data()\n",
    "users_df = fr.load_users_data()\n",
    "receipts_df = fr.load_receipts_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking data quality before Relational Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brands data\n",
    "\n",
    "#### Null values\n",
    "The most important information like barcode, name and id are non null here. But all other information has null values that makes it difficult for us to categorize the brands and make better decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barcode           0\n",
      "category        155\n",
      "categoryCode    650\n",
      "name              0\n",
      "topBrand        612\n",
      "_id.$oid          0\n",
      "cpg.$id.$oid      0\n",
      "cpg.$ref          0\n",
      "brandCode       234\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1167 entries, 0 to 1166\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   barcode       1167 non-null   object\n",
      " 1   category      1012 non-null   object\n",
      " 2   categoryCode  517 non-null    object\n",
      " 3   name          1167 non-null   object\n",
      " 4   topBrand      555 non-null    object\n",
      " 5   _id.$oid      1167 non-null   object\n",
      " 6   cpg.$id.$oid  1167 non-null   object\n",
      " 7   cpg.$ref      1167 non-null   object\n",
      " 8   brandCode     933 non-null    object\n",
      "dtypes: object(9)\n",
      "memory usage: 82.2+ KB\n"
     ]
    }
   ],
   "source": [
    "print(brands_df.isnull().sum())\n",
    "\n",
    "brands_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate barcodes\n",
    "\n",
    "Usually we expect unique entries for each barcode. If there are duplicates that indicates same item has different entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# find duplicates in barcode\n",
    "duplicates = brands_df[brands_df.duplicated(subset=['barcode'], keep=False)]\n",
    "\n",
    "print(len(duplicates[\"barcode\"].unique()))\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nTotal Duplicate entries in the dataframe:\")\n",
    "print(brands_df[brands_df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Barcode validity\n",
    "\n",
    "we can check the barcode validity by making some assumptions that the barcodes are numeric - do not include letters or any special characters and they have a certain length in this case 12\n",
    "\n",
    "Following cell shows that all the barcodes are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid barcodes (non-numeric or incorrect length):\n",
      "Empty DataFrame\n",
      "Columns: [barcode, category, categoryCode, name, topBrand, _id.$oid, cpg.$id.$oid, cpg.$ref, brandCode]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for invalid barcodes (assuming valid barcodes are numeric and of a certain length)\n",
    "print(\"\\nInvalid barcodes (non-numeric or incorrect length):\")\n",
    "valid_barcode_length = 12 \n",
    "invalid_barcodes = brands_df[~brands_df['barcode'].astype(str).str.isnumeric() | (brands_df['barcode'].astype(str).str.len() != valid_barcode_length)]\n",
    "print(invalid_barcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Values\n",
    "\n",
    "Identifier columns like user_id, created_date and role do not have any null values. This is promising for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212 entries, 0 to 211\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   active          212 non-null    bool          \n",
      " 1   role            212 non-null    object        \n",
      " 2   sign_up_source  207 non-null    object        \n",
      " 3   state           206 non-null    object        \n",
      " 4   user_id         212 non-null    object        \n",
      " 5   created_date    212 non-null    datetime64[ns]\n",
      " 6   last_login      172 non-null    datetime64[ns]\n",
      "dtypes: bool(1), datetime64[ns](2), object(4)\n",
      "memory usage: 10.3+ KB\n",
      "None\n",
      "active             0\n",
      "role               0\n",
      "sign_up_source     5\n",
      "state              6\n",
      "user_id            0\n",
      "created_date       0\n",
      "last_login        40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(users_df.info())\n",
    "# check for null values\n",
    "print(users_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates\n",
    "\n",
    "There are also no duplicates in user_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate userIds\n",
    "duplicates = users_df[users_df.duplicated(subset=['user_id'], keep=False)]\n",
    "print(len(duplicates[\"user_id\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking validity of date columns\n",
    "\n",
    "Any created, modified, login dates should not be later than current timestamp\n",
    "Login date should not be earlier than created date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [active, role, sign_up_source, state, user_id, created_date, last_login]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [active, role, sign_up_source, state, user_id, created_date, last_login]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [active, role, sign_up_source, state, user_id, created_date, last_login]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# check if created_data and last_login are later than current date\n",
    "users_df['created_date'] = pd.to_datetime(users_df['created_date'])\n",
    "users_df['last_login'] = pd.to_datetime(users_df['last_login'])\n",
    "print(users_df[users_df['created_date'] > pd.Timestamp.now()])\n",
    "print(users_df[users_df['last_login'] > pd.Timestamp.now()])\n",
    "\n",
    "# check if login date is earlier than created date\n",
    "print(users_df[users_df['last_login'] < users_df['created_date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is by far the cleanest data we got with very few null values and usage of well defined data types. Although the original json can be made more efficient with reducing nested structures for date and user_id, which we can easily cleanup in a python script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receipts data\n",
    "\n",
    "#### Null values\n",
    "Identifier columns like _id, user_id and decision making column rewards_receipt_status are non-null which allows us to use the data for parts of our decision making. From the relational model user_id will be a foreign key from users table so that's a good sign\n",
    "\n",
    "Other columns have more than 50% null values which is concerning. We can make some transformations as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonusPointsEarned          575\n",
      "bonusPointsEarnedReason    575\n",
      "pointsEarned               510\n",
      "purchasedItemCount         484\n",
      "rewardsReceiptItemList     440\n",
      "rewardsReceiptStatus         0\n",
      "totalSpent                 435\n",
      "userId                       0\n",
      "_id.$oid                     0\n",
      "createDate.$date             0\n",
      "dateScanned.$date            0\n",
      "finishedDate.$date         551\n",
      "modifyDate.$date             0\n",
      "pointsAwardedDate.$date    582\n",
      "purchaseDate.$date         448\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1119 entries, 0 to 1118\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   bonusPointsEarned        544 non-null    float64\n",
      " 1   bonusPointsEarnedReason  544 non-null    object \n",
      " 2   pointsEarned             609 non-null    object \n",
      " 3   purchasedItemCount       635 non-null    float64\n",
      " 4   rewardsReceiptItemList   679 non-null    object \n",
      " 5   rewardsReceiptStatus     1119 non-null   object \n",
      " 6   totalSpent               684 non-null    object \n",
      " 7   userId                   1119 non-null   object \n",
      " 8   _id.$oid                 1119 non-null   object \n",
      " 9   createDate.$date         1119 non-null   int64  \n",
      " 10  dateScanned.$date        1119 non-null   int64  \n",
      " 11  finishedDate.$date       568 non-null    float64\n",
      " 12  modifyDate.$date         1119 non-null   int64  \n",
      " 13  pointsAwardedDate.$date  537 non-null    float64\n",
      " 14  purchaseDate.$date       671 non-null    float64\n",
      "dtypes: float64(5), int64(3), object(7)\n",
      "memory usage: 131.3+ KB\n"
     ]
    }
   ],
   "source": [
    "print(receipts_df.isnull().sum())\n",
    "receipts_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates\n",
    "\n",
    "Receipt ids should not be duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "duplicates = receipts_df[receipts_df.duplicated(subset=['_id.$oid'], keep=False)]\n",
    "\n",
    "print(len(duplicates[\"_id.$oid\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding points columns\n",
    "\n",
    "Points_earned and bonus_points_earned should be float columns.\n",
    "\n",
    "Assuming points_earned Column is the total points Earned, we don't have any columns that have bonus_pointed_earned greater than points_earned.\n",
    "\n",
    "Points earned should not be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with BonusPointsEarned > PointsEarned:\n",
      "0\n",
      "Number of rows with negative pointsEarned:\n",
      "0\n",
      "Number of rows with negative bonusPointsEarned:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "receipts_df_temp = receipts_df\n",
    "\n",
    "# Assuming PointsEarned column is the total points earned by the user\n",
    "# if the value is null update it with BonusPointsEarned\n",
    "receipts_df_temp['pointsEarned'] = receipts_df_temp['pointsEarned'].fillna(receipts_df_temp['bonusPointsEarned'])\n",
    "\n",
    "# convert pointsEarned column to float\n",
    "receipts_df_temp['pointsEarned'] = receipts_df_temp['pointsEarned'].astype(float)\n",
    "\n",
    "# number of rows with BonusPointsEarned > PointsEarned\n",
    "print(\"Number of rows with BonusPointsEarned > PointsEarned:\")\n",
    "print(len(receipts_df_temp[receipts_df_temp['bonusPointsEarned'] > receipts_df_temp['pointsEarned']]))\n",
    "\n",
    "# check for negative values in pointsEarned\n",
    "print(\"Number of rows with negative pointsEarned:\")\n",
    "print(len(receipts_df[receipts_df['pointsEarned'] < 0]))\n",
    "\n",
    "# check for negative values in bonusPointsEarned\n",
    "print(\"Number of rows with negative bonusPointsEarned:\")\n",
    "print(len(receipts_df[receipts_df['bonusPointsEarned'] < 0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check validity of dates columns\n",
    "\n",
    "Any date columns should not be later than current time stamp\n",
    "\n",
    "modify_date should not be earlier than create_date\n",
    "\n",
    "finished_date and points_awarded_date should not be earlier than create_date and date_scanned\n",
    "\n",
    "purchase_date should not be later than date_scanned. There are 13 rows with purchase date later than date scanned.\n",
    "\n",
    "**Note:** Not all scenarios are covered in the code below. We are just trying to get the basic understanding of the date columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with createDate later than current date:\n",
      "0\n",
      "Number of rows with purchaseDate later than current date:\n",
      "0\n",
      "Number of rows with dateScanned later than current date:\n",
      "0\n",
      "Number of rows with purchaseDate later than date_scanned:\n",
      "13\n",
      "Number of rows with finishedDate later than current date:\n",
      "0\n",
      "Number of rows with finishedDate earlier than dateScanned or createdate:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# modify createDate.$date to datetime format\n",
    "receipts_df['create_date'] = pd.to_datetime(receipts_df['createDate.$date'], unit='ms')\n",
    "# check if createDate is later than current date\n",
    "print(\"Number of rows with createDate later than current date:\")\n",
    "print(len(receipts_df[receipts_df['create_date'] > pd.Timestamp.now()]))\n",
    "\n",
    "# modify purchaseDate.$date to datetime format\n",
    "receipts_df['purchase_date'] = pd.to_datetime(receipts_df['purchaseDate.$date'], unit='ms')\n",
    "# check if purchaseDate is later than current date\n",
    "print(\"Number of rows with purchaseDate later than current date:\")\n",
    "print(len(receipts_df[receipts_df['purchase_date'] > pd.Timestamp.now()]))\n",
    "\n",
    "# modify datescanned.$date to datetime format\n",
    "receipts_df['date_scanned'] = pd.to_datetime(receipts_df['dateScanned.$date'], unit='ms')\n",
    "# check if dateScanned is later than current date\n",
    "print(\"Number of rows with dateScanned later than current date:\")\n",
    "print(len(receipts_df[receipts_df['date_scanned'] > pd.Timestamp.now()]))\n",
    "\n",
    "# check if purchaseDate is later than dateScanned\n",
    "print(\"Number of rows with purchaseDate later than date_scanned:\")\n",
    "print(len(receipts_df[receipts_df['purchase_date'] > receipts_df['date_scanned']]))\n",
    "\n",
    "# modify finishedDate.$date to datetime format\n",
    "receipts_df['finished_date'] = pd.to_datetime(receipts_df['finishedDate.$date'], unit='ms')\n",
    "# check if finishedDate is later than current date\n",
    "print(\"Number of rows with finishedDate later than current date:\")\n",
    "print(len(receipts_df[receipts_df['finished_date'] > pd.Timestamp.now()]))\n",
    "\n",
    "# check if finishedDate is earlier than dateScanned, createdate\n",
    "print(\"Number of rows with finishedDate earlier than dateScanned or createdate:\")\n",
    "print(len(receipts_df[(receipts_df['finished_date'] < receipts_df['date_scanned']) | (receipts_df['finished_date'] < receipts_df['create_date'])]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Quality exploration in the rest of the notebook is on extracted data as we see in the Entity relationship model. There might be slight differences in the results when compared with using the raw data from JSON files. Assuming our long term vision is to store the data in a structured format in a data warehouse we want to understand the data quality of the modeled data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receipt Item list\n",
    "\n",
    "We cannot do any duplicate checks on the receipt_item_list table as we do not expect any unique identifiers in this table. Just by checking the info of the dataframe it is clear that most columns have significant null values. \n",
    "\n",
    "More than half of the receipts are missing product_id that makes it difficult for us to match them with the product and brands tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6941 entries, 0 to 6940\n",
      "Data columns (total 24 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   receipt_id                             6941 non-null   object \n",
      " 1   product_id                             3090 non-null   object \n",
      " 2   final_price                            6767 non-null   object \n",
      " 3   needs_fetch_review                     813 non-null    object \n",
      " 4   partner_item_id                        6941 non-null   object \n",
      " 5   prevent_target_gap_points              358 non-null    object \n",
      " 6   quantity_purchased                     6767 non-null   float64\n",
      " 7   user_flagged_barcode                   337 non-null    object \n",
      " 8   user_flagged_new_item                  323 non-null    object \n",
      " 9   user_flagged_price                     299 non-null    object \n",
      " 10  user_flagged_quantity                  299 non-null    float64\n",
      " 11  needs_fetch_review_reason              219 non-null    object \n",
      " 12  points_not_awarded_reason              340 non-null    object \n",
      " 13  points_payer_id                        1267 non-null   object \n",
      " 14  rewards_group                          1731 non-null   object \n",
      " 15  user_flagged_description               205 non-null    object \n",
      " 16  rewards_product_partner_id             2269 non-null   object \n",
      " 17  discounted_item_price                  5769 non-null   object \n",
      " 18  original_receipt_item_text             5760 non-null   object \n",
      " 19  original_metabrite_quantity_purchased  15 non-null     float64\n",
      " 20  points_earned                          927 non-null    object \n",
      " 21  target_price                           378 non-null    object \n",
      " 22  original_final_price                   9 non-null      object \n",
      " 23  price_after_coupon                     956 non-null    object \n",
      "dtypes: float64(3), object(21)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "receipt_item_list = fr.create_receipt_items_table(receipts_df)\n",
    "print(receipt_item_list.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Purchased Item count\n",
    "\n",
    "We are expecting the count of purchased items from top level receipts table to match the total of quantity purchased on from receipt_items_list table. Out of 1119 receipts 533 do not have matching item count. This could be because of null values in the receipt_item_list table or because the app read the values wrong when the receipt is scanned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with total_quantity_purchased not equal to item_count:\n",
      "533\n"
     ]
    }
   ],
   "source": [
    "# check total_quantity_purchased per receipt_id is same as item_count in receipts_df\n",
    "# group by receipt_id and sum total_quantity_purchased\n",
    "grouped_df = receipt_item_list.groupby('receipt_id')['quantity_purchased'].sum().reset_index()\n",
    "# merge with receipts_df to compare with item_count\n",
    "receipts_df_grouped = receipts_df.merge(grouped_df, right_on='receipt_id', left_on=\"_id.$oid\", how='left', suffixes=('', '_sum'))\n",
    "print(\"Number of rows with total_quantity_purchased not equal to item_count:\")\n",
    "print(len(receipts_df_grouped[receipts_df_grouped['quantity_purchased'] != receipts_df_grouped['purchasedItemCount']]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "* We have obtained high-quality user data due to the implementation of a standardized and fixed input mechanism.\n",
    "* Brands and products cannot be categorized as expected in the Entity Relation model due to null values, which prevent the establishment of proper unique identifiers for these tables. To resolve this data quality issue, it is recommended to separate user-facing data from backend payer data. Columns such as metabrite_id, payer_id, and partner_item_id can be stored in a separate table, while efforts should be made to improve user-facing information like product_id, brand_name, and user_flags to avoid null values.\n",
    "* Fortunately, there are no duplicates in the tables where it matters the most.\n",
    "* It is important to enforce strict rules on the date columns. For example, the purchase date should not be later than the date scanned. Our data contains 13 records that violate this rule.\n",
    "* An interesting observation is that the total purchased item count does not match between the high-level receipts table and the receipt_items_list. This discrepancy could be resolved by improving the model for receipt scanning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
